{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5Ng-_HyW5LP"
   },
   "source": [
    "# Terrier Learning to Rank Examples\n",
    "\n",
    "This notebook demonstrates the use of Pyterrier in a learning-to-rank fashion.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Lets install pyterrier, as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "eypl7XPrkifV",
    "outputId": "e042ffb0-8ee5-4d95-c8bc-7e2895df541f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-terrier\n",
      "  Cloning https://github.com/terrier-org/pyterrier.git to /tmp/pip-install-5ukk_67p/python-terrier\n",
      "  Running command git clone -q https://github.com/terrier-org/pyterrier.git /tmp/pip-install-5ukk_67p/python-terrier\n",
      "Collecting chest\n",
      "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
      "Collecting deprecation\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting matchpy\n",
      "  Downloading matchpy-0.5.3-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 3.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.8/dist-packages (from python-terrier) (1.1.4)\n",
      "Collecting pyjnius~=1.3.0\n",
      "  Downloading pyjnius-1.3.0-cp38-cp38-manylinux2010_x86_64.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytrec_eval\n",
      "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/lib/python3/dist-packages (from python-terrier) (2.22.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 21.1 MB/s eta 0:00:01     |████████████████████████████▍   | 22.9 MB 21.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.54.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 8.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.8/dist-packages (from deprecation->python-terrier) (20.4)\n",
      "Collecting multiset<3.0,>=2.0\n",
      "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting hopcroftkarp<2.0,>=1.2\n",
      "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->python-terrier) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->python-terrier) (2020.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.7.0 in /usr/lib/python3/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.14.0)\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.21-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 26.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: python-terrier, chest, pytrec-eval, sklearn, wget, hopcroftkarp\n",
      "  Building wheel for python-terrier (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.3.0.dev0-py3-none-any.whl size=55183 sha256=9c370e7f96d39d9511237f81264972bc7da62a3495b3de895b50ea94a5e004a0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rui0qtoa/wheels/92/00/3b/91460ee205c531cfa11bb4da2b9804ff1a4d57d77d175e7496\n",
      "  Building wheel for chest (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7620 sha256=f6ae81246f02b4b2e89446ea2cc590afa78396e827fff3e8fefcc375d9c42df3\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/10/0c/3c77925ea9d4deccf5e0a06a27a2c4cea4464bb57d68015eba\n",
      "  Building wheel for pytrec-eval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytrec-eval: filename=pytrec_eval-0.5-cp38-cp38-linux_x86_64.whl size=299692 sha256=9cc79c6c61aedb620365b9de5588ca6f25fc77f5bc8b61c04fca74cc91f95fc8\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/5a/e7/115104a6d6ebacea7cbd7434fdba04bd06b6756820994a326e\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=32279248de6d432aa4cc5f518bd9333d04f9303b5a8f283637f39792e45b69ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=ccaec85a35a9d6ff9dc5f4e5ec4912af6d36a71a0641c487750f671cc74bdf36\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
      "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18092 sha256=e008df459f912917876ec1bf8f882f8d2e0ccc3dfd296448f1072f3552906b02\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/f7/29/5c31600b478c23a3793be7cea9889d5eccb1e7ef40fef5e34e\n",
      "Successfully built python-terrier chest pytrec-eval sklearn wget hopcroftkarp\n",
      "Installing collected packages: heapdict, chest, deprecation, multiset, hopcroftkarp, matchpy, cython, pyjnius, pytrec-eval, scipy, joblib, threadpoolctl, scikit-learn, sklearn, tqdm, wget, python-terrier\n",
      "Successfully installed chest-0.2.3 cython-0.29.21 deprecation-2.1.0 heapdict-1.0.1 hopcroftkarp-1.2.5 joblib-0.17.0 matchpy-0.5.3 multiset-2.1.1 pyjnius-1.3.0 python-terrier-0.3.0.dev0 pytrec-eval-0.5 scikit-learn-0.23.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0 tqdm-4.54.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install python-terrier\n",
    "!pip3 install --upgrade git+https://github.com/terrier-org/pyterrier.git#egg=python-terrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5thmTselkuBv"
   },
   "source": [
    "## Init \n",
    "\n",
    "You must run pt.init() before other pyterrier functions and classes\n",
    "\n",
    "Arguments:    \n",
    "- `version` - terrier IR version e.g. \"5.2\"    \n",
    "- `mem` - megabytes allocated to java e.g. 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPK5k4g2kkKo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terrier-assemblies 5.3  jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
      "Done\n",
      "terrier-python-helper 0.0.4  jar not found, downloading to /root/.pyterrier...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.1.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 148.9 MB 341 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.19.4)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5BmNjqoXGow"
   },
   "source": [
    "## Load Files and Index\n",
    "\n",
    "Again, lets focus on the small Vaswani test collection. Its easily accessible via the dataset API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MCH20mGB8EG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani index to /root/.pyterrier/corpora/vaswani/index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data.direct.bf: 100%|██████████| 327k/327k [00:00<00:00, 6.63MiB/s]\n",
      "data.document.fsarrayfile: 100%|██████████| 190k/190k [00:00<00:00, 7.26MiB/s]\n",
      "data.inverted.bf: 100%|██████████| 301k/301k [00:00<00:00, 8.33MiB/s]\n",
      "data.lexicon.fsomapfile: 100%|██████████| 651k/651k [00:00<00:00, 11.1MiB/s]\n",
      "data.lexicon.fsomaphash: 100%|██████████| 777/777 [00:00<00:00, 1.13MiB/s]\n",
      "data.lexicon.fsomapid: 100%|██████████| 30.3k/30.3k [00:00<00:00, 4.39MiB/s]\n",
      "data.meta.idx: 100%|██████████| 89.3k/89.3k [00:00<00:00, 5.12MiB/s]\n",
      "data.meta.zdata: 100%|██████████| 168k/168k [00:00<00:00, 6.77MiB/s]\n",
      "data.properties: 4.10kiB [00:00, 2.02MiB/s]                \n",
      "query-text.trec: 10.7kiB [00:00, 2.09MiB/s]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani topics to /root/.pyterrier/corpora/vaswani/query-text.trec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qrels: 24.3kiB [00:00, 4.14MiB/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani qrels to /root/.pyterrier/corpora/vaswani/qrels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.datasets.get_dataset(\"vaswani\")\n",
    "\n",
    "indexref = dataset.get_index()\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8hUuA_KKPUH"
   },
   "source": [
    "## Multi-stage Retrieval\n",
    "\n",
    "In this experiment, we will be re-ranking the results obtaind from a BM25 ranking, by adding more features. Will then pass these for re-ranking by a regression technique, such as Random Forests.\n",
    "\n",
    "Conceptually, this pipeline has three stages:\n",
    "1. PL2 ranking\n",
    "2. Re-rank by each of the feaures (\"TF_IDF\" and \"PL2\")\n",
    "3. Apply the RandomForests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEjmsD3ya8Pc"
   },
   "outputs": [],
   "source": [
    "#this ranker will make the candidate set of documents for each query\n",
    "BM25 = pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"})\n",
    "\n",
    "#these rankers we will use to re-rank the BM25 results\n",
    "TF_IDF =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"TF_IDF\"})\n",
    "PL2 =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"PL2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPH = pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"DPH\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T07YF3-ULGsG"
   },
   "source": [
    "OK, so how do we combine these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTLh6SrCLGM0"
   },
   "outputs": [],
   "source": [
    "pipe = DPH >> (TF_IDF ** PL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7M4cUxCLMTo"
   },
   "source": [
    "Here, we are using two Pyterrer operators:\n",
    " - `>>` means \"then\", and takes the output documents of BM25 and puts them into the next stage. This means that TF_IDF and PL2 are ONLY applied on the documents that BM25 has identified.\n",
    " - `**` means feature-union - which makes each ranker into a feature in the `features` column of the results.\n",
    "\n",
    "Lets give a look at the output to see what it gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "DYNOf_TwLp0Z",
    "outputId": "d9779320-58f8-4197-aa91-f05f7d05a8c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score_x</th>\n",
       "      <th>query</th>\n",
       "      <th>docid_x</th>\n",
       "      <th>rank_x</th>\n",
       "      <th>query_x</th>\n",
       "      <th>docid_y</th>\n",
       "      <th>rank_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>query_y</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10702</td>\n",
       "      <td>10703</td>\n",
       "      <td>0</td>\n",
       "      <td>13.472012</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>10702</td>\n",
       "      <td>0</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>10702</td>\n",
       "      <td>0</td>\n",
       "      <td>13.472012</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>[7.38109017620895, 6.9992254918907575, 13.4720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1055</td>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "      <td>12.517082</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>12.517082</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>[6.857899681644975, 6.358419229871986, 12.5170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4885</td>\n",
       "      <td>4886</td>\n",
       "      <td>2</td>\n",
       "      <td>12.228161</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>4885</td>\n",
       "      <td>2</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>4885</td>\n",
       "      <td>2</td>\n",
       "      <td>12.228161</td>\n",
       "      <td>chemical end:2</td>\n",
       "      <td>[6.69960466053696, 6.181368165774688, 12.22816...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid  docno  rank    score_x           query  docid_x  rank_x  \\\n",
       "0   1  10702  10703     0  13.472012  chemical end:2    10702       0   \n",
       "1   1   1055   1056     1  12.517082  chemical end:2     1055       1   \n",
       "2   1   4885   4886     2  12.228161  chemical end:2     4885       2   \n",
       "\n",
       "          query_x  docid_y  rank_y    score_y         query_y  \\\n",
       "0  chemical end:2    10702       0  13.472012  chemical end:2   \n",
       "1  chemical end:2     1055       1  12.517082  chemical end:2   \n",
       "2  chemical end:2     4885       2  12.228161  chemical end:2   \n",
       "\n",
       "                                            features  \n",
       "0  [7.38109017620895, 6.9992254918907575, 13.4720...  \n",
       "1  [6.857899681644975, 6.358419229871986, 12.5170...  \n",
       "2  [6.69960466053696, 6.181368165774688, 12.22816...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.transform(\"chemical end:2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZMvd3qjLkrs"
   },
   "source": [
    "See, we now have a \"features\" column with numbers representing the TF_IDF and PL2 feature scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ye6ZpcZaMBjT"
   },
   "source": [
    "*A note about efficiency*: doing retrieval, then re-ranking the documents again can be slow. For this reason, Terrier has a FeaturesBatchRetrieve. Lets try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "5gCHuDiJMNJZ",
    "outputId": "cd0d5320-4d08-417a-d2dd-08e07f500793"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>rank</th>\n",
       "      <th>features</th>\n",
       "      <th>docno</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10702</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.38109017620895, 6.9992254918907575]</td>\n",
       "      <td>10703</td>\n",
       "      <td>13.472012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.857899681644975, 6.358419229871986]</td>\n",
       "      <td>1056</td>\n",
       "      <td>12.517082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid  rank                                features  docno      score\n",
       "0   1  10702     0  [7.38109017620895, 6.9992254918907575]  10703  13.472012\n",
       "1   1   1055     1  [6.857899681644975, 6.358419229871986]   1056  12.517082"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbr = pt.FeaturesBatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"}, features=[\"WMODEL:TF_IDF\", \"WMODEL:PL2\"]) \n",
    "#lets look at the top 2 results\n",
    "(fbr %2).transform(\"chemical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fo567qmCMZ41"
   },
   "source": [
    "However, this kind of optimisation is common in Pyterrier, so Pyterrier actually supports automatic pipeline optimisation, using the `.compile()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "jmrnqg9YMpl2",
    "outputId": "70882fb4-8057-4014-ece8-899a593e4cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying 8 rules\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "require rank to be present in the result set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1bc92e7ea800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipe_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpipe_fast\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chemical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyterrier/transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, topics_and_res)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_and_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m\"rank\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"require rank to be present in the result set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# this assumes that the minimum rank cutoff is model.FIRST_RANK, i.e. 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: require rank to be present in the result set"
     ]
    }
   ],
   "source": [
    "pipe_fast = pipe.compile()\n",
    "(pipe_fast %2).transform(\"chemical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "siS6M5t_hugs"
   },
   "source": [
    "Finally, often we want our initial retrieval score to be a feature also. We can do this in one of two ways:\n",
    " - by adding a `SAMPLE` feature to FeaturesBatchRetrieve\n",
    " - or in the original feature-union definition, including an IdentityTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "iXxeKfPXhuPA",
    "outputId": "25a8c80c-c277-476e-c243-7c6f9d5989cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score_x</th>\n",
       "      <th>query</th>\n",
       "      <th>docid_x</th>\n",
       "      <th>rank_x</th>\n",
       "      <th>query_x</th>\n",
       "      <th>docid_y</th>\n",
       "      <th>rank_y</th>\n",
       "      <th>score_y</th>\n",
       "      <th>query_y</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6278</td>\n",
       "      <td>6279</td>\n",
       "      <td>0</td>\n",
       "      <td>6.17840</td>\n",
       "      <td>chemical</td>\n",
       "      <td>6278</td>\n",
       "      <td>0</td>\n",
       "      <td>chemical</td>\n",
       "      <td>6278</td>\n",
       "      <td>0</td>\n",
       "      <td>6.17840</td>\n",
       "      <td>chemical</td>\n",
       "      <td>[6.178399717192183, 6.12819661651192, 5.639397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2519</td>\n",
       "      <td>2520</td>\n",
       "      <td>1</td>\n",
       "      <td>4.80698</td>\n",
       "      <td>chemical</td>\n",
       "      <td>2519</td>\n",
       "      <td>1</td>\n",
       "      <td>chemical</td>\n",
       "      <td>2519</td>\n",
       "      <td>1</td>\n",
       "      <td>4.80698</td>\n",
       "      <td>chemical</td>\n",
       "      <td>[4.806979944375463, 5.655311070061918, 5.11360...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid docno  rank  score_x     query  docid_x  rank_x   query_x  \\\n",
       "0   1   6278  6279     0  6.17840  chemical     6278       0  chemical   \n",
       "1   1   2519  2520     1  4.80698  chemical     2519       1  chemical   \n",
       "\n",
       "   docid_y  rank_y  score_y   query_y  \\\n",
       "0     6278       0  6.17840  chemical   \n",
       "1     2519       1  4.80698  chemical   \n",
       "\n",
       "                                            features  \n",
       "0  [6.178399717192183, 6.12819661651192, 5.639397...  \n",
       "1  [4.806979944375463, 5.655311070061918, 5.11360...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbr = pt.FeaturesBatchRetrieve(indexref, controls = {\"wmodel\": \"DPH\"}, features=[\"SAMPLE\", \"WMODEL:TF_IDF\", \"WMODEL:PL2\"]) \n",
    "pipe = DPH >> (pt.transformer.IdentityTransformer() ** TF_IDF ** PL2)\n",
    "\n",
    "(pipe %2).transform(\"chemical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R47HlFoMYAhi"
   },
   "source": [
    "# Learning models and re-ranking\n",
    "\n",
    "Ok, lets get onto the actual machine learning. We can use standard Python ML techniques. We will demonstrate a few here, including from sci-kit learn and xgBoost.\n",
    "\n",
    "In each case, the pattern is the same:\n",
    " - Create a transformer that does the re-ranking\n",
    " - Call the fit() method on the created object with the training topics (and validation topics as necessary)\n",
    " - Evaluate the results with the Experiment function by using the test topics\n",
    "\n",
    " Firstly, lets separate our topics into train/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7r10lR3DvzM"
   },
   "outputs": [],
   "source": [
    "train_topics, valid_topics, test_topics = np.split(topics, [int(.6*len(topics)), int(.8*len(topics))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3PYw_jasN6Vk"
   },
   "source": [
    "## sci-kit learn RandomForestRegressor\n",
    "\n",
    "Our first learning-to-rank will be done using sci-kit learn's [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). \n",
    "\n",
    "We use `pt.piptlines.LTR_pipeline`, which is a pyterrier transformer that passes the document features as \"X\" features to RandomForest. To learn the model (called fitting) the RandomForest, we invoke the `fit()` method - on the entire pipeline, specifying the queries (topics) and relevance assessment (qrels). The latter for the \"Y\" labels for the RandomForest fitting.\n",
    "\n",
    "NB: due to their bootstrap nature, Random Forests do not overfit, so we do not provide validation data to `fit()`.\n",
    "\n",
    "On the other hand, we could use any regression learner from sklearn, and adjust its parameters ourselves.\n",
    "\n",
    "Finally, we Experiment() on the test data to compare performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "YTI_ax4K19nl",
    "outputId": "186b0de0-4793-4afc-c463-c9082a2129ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 algorithm</td>\n",
       "      <td>0.217680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL2 Baseline</td>\n",
       "      <td>0.206031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LTR Baseline</td>\n",
       "      <td>0.129050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name       map\n",
       "0  BM25 algorithm  0.217680\n",
       "1    PL2 Baseline  0.206031\n",
       "2    LTR Baseline  0.129050"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "BaselineLTR = fbr >> pt.pipelines.LTR_pipeline(RandomForestRegressor(n_estimators=400))\n",
    "BaselineLTR.fit(train_topics, qrels)\n",
    "\n",
    "results = pt.pipelines.Experiment([BM25, PL2, BaselineLTR], test_topics, qrels, [\"map\"], names=[\"BM25 algorithm\", \"PL2 Baseline\", \"LTR Baseline\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25 algorithm</td>\n",
       "      <td>0.217680</td>\n",
       "      <td>0.551313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL2 Baseline</td>\n",
       "      <td>0.206031</td>\n",
       "      <td>0.537795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LTR Baseline</td>\n",
       "      <td>0.129050</td>\n",
       "      <td>0.475305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name       map      ndcg\n",
       "0  BM25 algorithm  0.217680  0.551313\n",
       "1    PL2 Baseline  0.206031  0.537795\n",
       "2    LTR Baseline  0.129050  0.475305"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pt.pipelines.Experiment([BM25, PL2, BaselineLTR], test_topics, qrels, [\"map\", \"ndcg\"], names=[\"BM25 algorithm\", \"PL2 Baseline\", \"LTR Baseline\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGw58PCuumuT"
   },
   "source": [
    "## XgBoost Pipeline\n",
    "\n",
    "We now demonstrate the use of a LambdaMART implementation from [xgBoost](https://xgboost.readthedocs.io/en/latest/). Again, pyTerrier provides a transformer object, namely `XGBoostLTR_pipeline`, which takes in the constrcutor the actual xgBoost model that you want to train. We took the xgBoost configuration from [their example code](https://github.com/dmlc/xgboost/blob/master/demo/rank/rank.py).\n",
    "\n",
    "Call the `fit()` method on the full pipeline with the training and validation topics.\n",
    "\n",
    "Evaluate the results with the Experiment function by using the test topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM0r8EgFuGtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:18:46] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "params = {'objective': 'rank:ndcg', \n",
    "          'learning_rate': 0.1, \n",
    "          'gamma': 1.0, 'min_child_weight': 0.1,\n",
    "          'max_depth': 6,\n",
    "          'verbose': 2,\n",
    "          'random_state': 42 \n",
    "         }\n",
    "\n",
    "BaseLTR_LM = fbr >> pt.pipelines.XGBoostLTR_pipeline(xgb.sklearn.XGBRanker(**params))\n",
    "BaseLTR_LM.fit(train_topics, qrels, valid_topics, qrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVXoNhzSP-k2"
   },
   "source": [
    "And evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "Dn56DKZMTQ_m",
    "outputId": "6688d85e-8599-4f11-db18-231abd0d7aee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL2 Baseline</td>\n",
       "      <td>0.206031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LambdaMART</td>\n",
       "      <td>0.211269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       map\n",
       "0  PL2 Baseline  0.206031\n",
       "1    LambdaMART  0.211269"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allresultsLM = pt.pipelines.Experiment([PL2, BaseLTR_LM],\n",
    "                                test_topics,                                  \n",
    "                                qrels, [\"map\"], \n",
    "                                names=[\"PL2 Baseline\", \"LambdaMART\"])\n",
    "allresultsLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AND' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-180763d56e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AND' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Learning to Rank Examples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
