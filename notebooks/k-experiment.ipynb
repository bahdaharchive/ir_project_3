{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webtrack_gov():\n",
    "#     for k in [\"trec-wt-2002\", \"trec-wt-2003\", \"trec-wt-2004\"]:\n",
    "    for k in [\"trec-wt-2004\"]:\n",
    "        ds = pt.get_dataset(k)\n",
    "        print(dir(ds))\n",
    "#         for t in [\"np\", \"td\", \"hp\"]:\n",
    "        for t in [\"all\"]:\n",
    "            topics = ds.get_topics(t)\n",
    "            indexref=ds.get_index\n",
    "            qrels = ds.get_qrels(t)\n",
    "            return (qrels, topics, indexref)\n",
    "\n",
    "qrels, topics, indexref = get_webtrack_gov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.datasets.get_dataset(\"vaswani\")\n",
    "#dataset = pt.datasets.get_dataset(\"trec-wt-2012\")\n",
    "print(dataset)\n",
    "indexref = dataset.get_index()\n",
    "print(type(indexref))\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(qrels))\n",
    "print(len(topics))\n",
    "print(len(qrels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this ranker will make the candidate set of documents for each query\n",
    "BM25 = pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"BM25\"})\n",
    "\n",
    "#these rankers we will use to re-rank the BM25 results\n",
    "TF_IDF =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"TF_IDF\"})\n",
    "PL2 =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"PL2\"})\n",
    "DPH = pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"DPH\"})\n",
    "PL2F =  pt.BatchRetrieve(indexref, controls = {\"wmodel\": \"PL2F\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch_retriever = pt.FeaturesBatchRetrieve(indexref, features=[\"WMODEL:TF_IDF\", \"WMODEL:PL2\", \"WMODEL:DPH\", \"WMODEL:BM25\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(BM25 %2).transform(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PL2).transform(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_topics, valid_topics, test_topics = np.split(topics, [int(.6*len(topics)), int(.8*len(topics))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "ltr_model = fbr >> pt.pipelines.LTR_pipeline(RandomForestRegressor(n_estimators=400))\n",
    "ltr_model.fit(train_topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pt.pipelines.Experiment([TF_IDF, BM25, PL2, ltr_model], test_topics, qrels, [\"map\", \"ndcg\"], names=[\"TF-IDF\", \"BM25 algorithm\", \"PL2 Baseline\", \"LTR Random Forest\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # plotting libraries\n",
    "\n",
    "def run_experiment(trained_model, mop, start= 10, finish = 600, incrementer = 25, top_k_model = BM25, title=\"sample title\"):\n",
    "    k_list = []\n",
    "    moe_list = []\n",
    "    for k in range(start, finish, incrementer):\n",
    "        efficient_pipeline = top_k_model % k >> trained_model\n",
    "        results = pt.pipelines.Experiment([efficient_pipeline], test_topics, qrels, [mop], names=[\"model\"])\n",
    "        k_list.append(k)\n",
    "        moe_list.append(results[mop].iloc[0])\n",
    "        \n",
    "        plt.plot(k_list, moe_list)\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(mop)\n",
    "        file_name = title.replace(\" \", \"-\")\n",
    "        plt.title(title)\n",
    "        plt.savefig(file_name)\n",
    "        \n",
    "run_experiment(ltr_model, \"ndcg\", title = \"K's Affect on NDCG in Learning to Rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
